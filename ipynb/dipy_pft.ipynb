{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.data import get_fnames, default_sphere\n",
    "from dipy.direction import ProbabilisticDirectionGetter\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.io.image import load_nifti, load_nifti_data\n",
    "from dipy.io.stateful_tractogram import Space, StatefulTractogram\n",
    "from dipy.io.streamline import save_trk, load_trk\n",
    "from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,\n",
    "                                   auto_response)\n",
    "from dipy.tracking.local_tracking import (LocalTracking,\n",
    "                                          ParticleFilteringTracking)\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.tracking import utils\n",
    "from dipy.viz import window, actor, colormap, has_fury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enables/disables interactive visualization\n",
    "interactive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardi_fname, hardi_bval_fname, hardi_bvec_fname = get_fnames('stanford_hardi')\n",
    "label_fname = get_fnames('stanford_labels')\n",
    "f_pve_csf, f_pve_gm, f_pve_wm = get_fnames('stanford_pve_maps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, affine, hardi_img = load_nifti(hardi_fname, return_img=True)\n",
    "labels = load_nifti_data(label_fname)\n",
    "bvals, bvecs = read_bvals_bvecs(hardi_bval_fname, hardi_bvec_fname)\n",
    "gtab = gradient_table(bvals, bvecs)\n",
    "\n",
    "pve_csf_data = load_nifti_data(f_pve_csf)\n",
    "pve_gm_data = load_nifti_data(f_pve_gm)\n",
    "pve_wm_data, _, voxel_size = load_nifti(f_pve_wm, return_voxsize=True)\n",
    "\n",
    "shape = labels.shape\n",
    "\n",
    "response, ratio = auto_response(gtab, data, roi_radius=10, fa_thr=0.7)\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab, response)\n",
    "csd_fit = csd_model.fit(data, mask=pve_wm_data)\n",
    "\n",
    "dg = ProbabilisticDirectionGetter.from_shcoeff(csd_fit.shm_coeff,\n",
    "                                               max_angle=20.,\n",
    "                                               sphere=default_sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_mask = (labels == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(seed_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_mask = (labels == 2) + (labels == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58788"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(seed_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_mask[pve_wm_data < 0.5] = 0\n",
    "seeds = utils.seeds_from_mask(seed_mask, affine, density=2)\n",
    "\n",
    "\"\"\"\n",
    "CMC/ACT Stopping Criterion\n",
    "==========================\n",
    "Continuous map criterion (CMC) [Girard2014]_ and Anatomically-constrained\n",
    "tractography (ACT) [Smith2012]_ both uses PVEs information from\n",
    "anatomical images to determine when the tractography stops.\n",
    "Both stopping criterion use a trilinear interpolation\n",
    "at the tracking position. CMC stopping criterion uses a probability derived\n",
    "from the PVE maps to determine if the streamline reaches a 'valid' or 'invalid'\n",
    "region. ACT uses a fixed threshold on the PVE maps. Both stopping criterion can\n",
    "be used in conjunction with PFT. In this example, we used CMC.\n",
    "\"\"\"\n",
    "\n",
    "from dipy.tracking.stopping_criterion import CmcStoppingCriterion\n",
    "\n",
    "voxel_size = np.average(voxel_size[1:4])\n",
    "step_size = 0.2\n",
    "\n",
    "cmc_criterion = CmcStoppingCriterion.from_pve(pve_wm_data,\n",
    "                                              pve_gm_data,\n",
    "                                              pve_csf_data,\n",
    "                                              step_size=step_size,\n",
    "                                              average_voxel_size=voxel_size)\n",
    "\n",
    "# Particle Filtering Tractography\n",
    "pft_streamline_generator = ParticleFilteringTracking(dg,\n",
    "                                                     cmc_criterion,\n",
    "                                                     seeds,\n",
    "                                                     affine,\n",
    "                                                     max_cross=1,\n",
    "                                                     step_size=step_size,\n",
    "                                                     maxlen=1000,\n",
    "                                                     pft_back_tracking_dist=2,\n",
    "                                                     pft_front_tracking_dist=1,\n",
    "                                                     particle_count=15,\n",
    "                                                     return_all=False)\n",
    "streamlines = Streamlines(pft_streamline_generator)\n",
    "\n",
    "sft = StatefulTractogram(streamlines, hardi_img, Space.RASMM)\n",
    "save_trk(sft, \"tractogram_pft.trk\")\n",
    "\n",
    "# if has_fury:\n",
    "#     r = window.Renderer()\n",
    "#     r.add(actor.line(streamlines, colormap.line_colors(streamlines)))\n",
    "#     window.record(r, out_path='tractogram_pft.png',\n",
    "#                   size=(800, 800))\n",
    "#     if interactive:\n",
    "#         window.show(r)\n",
    "\n",
    "# \"\"\"\n",
    "# .. figure:: tractogram_pft.png\n",
    "#  :align: center\n",
    "\n",
    "#  **Corpus Callosum using particle filtering tractography**\n",
    "# \"\"\"\n",
    "\n",
    "# # Local Probabilistic Tractography\n",
    "# prob_streamline_generator = LocalTracking(dg,\n",
    "#                                           cmc_criterion,\n",
    "#                                           seeds,\n",
    "#                                           affine,\n",
    "#                                           max_cross=1,\n",
    "#                                           step_size=step_size,\n",
    "#                                           maxlen=1000,\n",
    "#                                           return_all=False)\n",
    "# streamlines = Streamlines(prob_streamline_generator)\n",
    "# sft = StatefulTractogram(streamlines, hardi_img, Space.RASMM)\n",
    "# save_trk(sft, \"tractogram_probabilistic_cmc.trk\")\n",
    "\n",
    "# if has_fury:\n",
    "#     r = window.Renderer()\n",
    "#     r.add(actor.line(streamlines, colormap.line_colors(streamlines)))\n",
    "#     window.record(r, out_path='tractogram_probabilistic_cmc.png',\n",
    "#                   size=(800, 800))\n",
    "#     if interactive:\n",
    "#         window.show(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft = load_trk('./tractogram_pft.trk', hardi_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlines = sft.streamlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.data import read_stanford_labels, fetch_stanford_t1, read_stanford_t1\n",
    "\n",
    "hardi_img, gtab, labels_img = read_stanford_labels()\n",
    "data = hardi_img.get_fdata()\n",
    "labels = labels_img.get_fdata()\n",
    "\n",
    "fetch_stanford_t1()\n",
    "t1 = read_stanford_t1()\n",
    "t1_data = t1.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.viz import window, actor, colormap as cmap\n",
    "\n",
    "# Enables/disables interactive visualization\n",
    "interactive = False\n",
    "\n",
    "# Make display objects\n",
    "color = cmap.line_colors(streamlines)\n",
    "cc_streamlines_actor = actor.line(streamlines,\n",
    "                                  cmap.line_colors(streamlines))\n",
    "\n",
    "vol_actor = actor.slicer(t1_data, affine=t1.affine)\n",
    "\n",
    "vol_actor.display(x=40)\n",
    "vol_actor2 = vol_actor.copy()\n",
    "vol_actor2.display(z=35)\n",
    "\n",
    "# Add display objects to canvas\n",
    "r = window.Renderer()\n",
    "r.add(vol_actor)\n",
    "r.add(vol_actor2)\n",
    "r.add(cc_streamlines_actor)\n",
    "\n",
    "r.set_camera(position=[-1, 0, 0.3], focal_point=[0, 0, 0], view_up=[0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window.show(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "window.record(r, n_frames=360, out_path='./pft/fig', path_numbering=True, az_ang=1,\n",
    "            size=(800, 800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = glob('./pft/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|â–         | 5/361 [00:00<00:08, 42.56it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ./whole_brain.mp4.\n",
      "Moviepy - Writing video ./whole_brain.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./whole_brain.mp4\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "from glob import glob\n",
    "imseq = mp.ImageSequenceClip(ll, fps=18)\n",
    "imseq.write_videofile('./whole_brain.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
